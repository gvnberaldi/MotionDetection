{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Motion Detection with Frame Differencing**\n",
    "\n",
    "In this notebook we will explore a simple method of moving object detection via Frame Differencing.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T09:09:47.511240Z",
     "start_time": "2024-05-19T09:09:47.502647Z"
    }
   },
   "source": [
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "sys.path.append(os.path.join(os.getcwd(), 'common_utils'))\n",
    "from common_utils.choose_dataset_and_video import get_random_choice\n",
    "from common_utils.get_moving_object_detections import get_contour_detections, draw_contours\n",
    "from common_utils.make_video import merge_images, add_text, make_video\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "notebook_id = 'TA'"
   ],
   "outputs": [],
   "execution_count": 131
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data\n",
    "\n",
    "We use the CD2014 or SBMnet dataset.\n",
    "\n",
    "The following are helper function to choose a random video and load the images in sequence"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T09:09:47.647967Z",
     "start_time": "2024-05-19T09:09:47.642817Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_directories(path):\n",
    "    \"\"\"Return a list of directories name on the specifed path\"\"\"\n",
    "    return [file for file in os.listdir(path) if os.path.isdir(os.path.join(path, file))]"
   ],
   "outputs": [],
   "execution_count": 132
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T09:09:47.690308Z",
     "start_time": "2024-05-19T09:09:47.684547Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_folder(dataset_path):\n",
    "    \"\"\"Call your executable for all sequences in all categories.\"\"\"\n",
    "    video_paths = []\n",
    "    for category in get_directories(dataset_path):\n",
    "        category_path = os.path.join(dataset_path, category)\n",
    "        for video in get_directories(category_path):\n",
    "            video_path = os.path.join(category_path, os.path.join(video, 'input'))\n",
    "            video_paths.append(video_path)\n",
    "    return video_paths"
   ],
   "outputs": [],
   "execution_count": 133
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T09:09:47.713140Z",
     "start_time": "2024-05-19T09:09:47.707552Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_images_from_folder(folder_path):\n",
    "    # Get a list of all files in the folder\n",
    "    files = os.listdir(folder_path)\n",
    "    # Filter for only jpg files and construct the full path for each\n",
    "    jpg_image_paths = [os.path.join(folder_path, file) for file in files if file.lower().endswith('.jpg')]\n",
    "    \n",
    "    return jpg_image_paths"
   ],
   "outputs": [],
   "execution_count": 134
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T09:09:47.758645Z",
     "start_time": "2024-05-19T09:09:47.740024Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset_path, chosen_dataset, random_category, random_sub_category = get_random_choice(notebook_id)\n",
    "print('Chosen dataset:', chosen_dataset)\n",
    "print('Chosen category:', random_category)\n",
    "print('Chosen sub_category:', random_sub_category)\n",
    "\n",
    "video_folder_path = os.path.join(dataset_path, random_category, random_sub_category, 'input')\n",
    "\n",
    "image_paths = get_images_from_folder(video_folder_path)\n",
    "results_folder_path = os.path.join(os.getcwd(), f'datasets\\\\results\\\\{chosen_dataset}_results') "
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen dataset: CDNet_2014\n",
      "Chosen category: baseline\n",
      "Chosen sub_category: highway\n"
     ]
    }
   ],
   "execution_count": 135
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **Get Motion Mask**\n",
    "In this step we get a thresholded image mask. This image mask will give us relative locations of all moving targets."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T09:09:47.791494Z",
     "start_time": "2024-05-19T09:09:47.785925Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_mask(frame1, frame2, adaptive=True, block_size=21, constant=5):\n",
    "    # convert to grayscale\n",
    "    frame1 = cv2.cvtColor(frame1, cv2.COLOR_RGB2GRAY)\n",
    "    frame2 = cv2.cvtColor(frame2, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # Compute the absolute difference between the two frames. This highlights the changes (i.e., movement) between the frames\n",
    "    frame_diff = cv2.absdiff(frame2, frame1)\n",
    "    # Apply a median blur with a 3x3 kernel to the frame difference. Blurring helps reduce noise and smooth the image, potentially eliminating isolated fluctuations\n",
    "    frame_diff = cv2.medianBlur(frame_diff, 3)\n",
    "    # Apply a simple threshold to create a binary mask of moving pixels\n",
    "    if adaptive:\n",
    "        mask = cv2.adaptiveThreshold(frame_diff, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, block_size, constant)\n",
    "    else:\n",
    "        _, mask = cv2.threshold(frame_diff, 30, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    return mask"
   ],
   "outputs": [],
   "execution_count": 136
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **Reference Frame Differencing**\n",
    "### Method\n",
    "1) Chose a reference frame (the first one in this case)\n",
    "2) Take Frame Difference: $d = reference frame - frame_{t}$\n",
    "3) Threshold frame difference to get mask\n",
    "4) Perform detection on mask via contour finding\n",
    "5) Draw bounding boxes"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T09:09:54.230184Z",
     "start_time": "2024-05-19T09:09:47.828400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# REFERENCE FRAME DIFFERENCING\n",
    "video_frames_rfd = []\n",
    "reference_frame = cv2.imread(image_paths[0])\n",
    "for idx in tqdm(range(1, len(image_paths)), total=len(image_paths), desc=\"Processing Frames\"):\n",
    "    # read frame\n",
    "    frame = cv2.imread(image_paths[idx])\n",
    "    \n",
    "    # get detections\n",
    "    mask = get_mask(reference_frame, frame, block_size=29, constant=9)\n",
    "    detections = get_contour_detections(mask, thresh=400, distance_threshold=13)\n",
    "    rgb_detections = draw_contours(frame, detections)\n",
    "\n",
    "    merged_frame = add_text(merge_images(cv2.cvtColor(mask, cv2.COLOR_GRAY2RGB), rgb_detections), 'REFERENCE FRAME DIFFERENCING')\n",
    "    # Append to list for video\n",
    "    video_frames_rfd.append(merged_frame)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Frames: 100%|█████████▉| 1699/1700 [00:06<00:00, 271.61it/s]\n"
     ]
    }
   ],
   "execution_count": 137
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T09:09:56.513994Z",
     "start_time": "2024-05-19T09:09:54.232182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "os.makedirs(os.path.join(results_folder_path, 'Reference Frame Differencing'), exist_ok=True)\n",
    "make_video(video_frames_rfd, os.path.join(results_folder_path, 'Reference Frame Differencing', f'{random_sub_category}.mp4'))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Frames: 100%|██████████| 1699/1699 [00:02<00:00, 748.92it/s]\n"
     ]
    }
   ],
   "execution_count": 138
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **Adjacent Frame Differencing**\n",
    "### Method\n",
    "1) Take Frame Difference: $d = frame_{t+1} - frame_{t}$\n",
    "2) Threshold frame difference to get mask\n",
    "3) Perform detection on mask via contour finding\n",
    "4) Draw bounding boxes"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T09:10:04.544286Z",
     "start_time": "2024-05-19T09:09:56.516991Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ADJACENT FRAME DIFFERENCING\n",
    "video_frames_afd = []\n",
    "for idx in tqdm(range(1, len(image_paths)), total=len(image_paths), desc=\"Processing Frames\"):\n",
    "    # read frame\n",
    "    frame1 = cv2.imread(image_paths[idx - 1])\n",
    "    frame2 = cv2.imread(image_paths[idx])\n",
    "    \n",
    "    # get detections\n",
    "    mask = get_mask(frame1, frame2, block_size=21, constant=5)\n",
    "    detections = get_contour_detections(mask, thresh=400, distance_threshold=40)\n",
    "    rgb_detections = draw_contours(frame2, detections)\n",
    "\n",
    "    merged_frame = add_text(merge_images(cv2.cvtColor(mask, cv2.COLOR_GRAY2RGB), rgb_detections), 'ADJACENT FRAME DIFFERENCING')\n",
    "\n",
    "    # Append to list for video\n",
    "    video_frames_afd.append(merged_frame)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Frames: 100%|█████████▉| 1699/1700 [00:07<00:00, 214.05it/s]\n"
     ]
    }
   ],
   "execution_count": 139
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T09:10:06.605104Z",
     "start_time": "2024-05-19T09:10:04.546287Z"
    }
   },
   "cell_type": "code",
   "source": [
    "os.makedirs(os.path.join(results_folder_path, 'Adjacent Frame Differencing'), exist_ok=True)\n",
    "make_video(video_frames_afd, os.path.join(results_folder_path, 'Adjacent Frame Differencing', f'{random_sub_category}.mp4'))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Frames: 100%|██████████| 1699/1699 [00:02<00:00, 831.52it/s]\n"
     ]
    }
   ],
   "execution_count": 140
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **Median Frame Differencing**\n",
    "### Method\n",
    "1) Calculate the median of buffered frames (previous n frame) to generate a reference frame\n",
    "2) Take Frame Difference: $d = median frame - frame_{t}$\n",
    "3) Threshold frame difference to get mask\n",
    "4) Perform detection on mask via contour finding\n",
    "5) Draw bounding boxes"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T09:10:31.421044Z",
     "start_time": "2024-05-19T09:10:06.608105Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import deque\n",
    "\n",
    "video_frames_mfd = []\n",
    "buffer_size = 5\n",
    "frame_buffer = deque(maxlen=buffer_size)\n",
    "for idx in tqdm(range(1, len(image_paths)), total=len(image_paths), desc=\"Processing Frames\"):\n",
    "    frame = cv2.imread(image_paths[idx])\n",
    "    frame_buffer.append(frame)\n",
    "    median_frame = np.median(np.array(frame_buffer), axis=0).astype(np.uint8)\n",
    "    \n",
    "     # get detections\n",
    "    mask = get_mask(median_frame, frame)\n",
    "    detections = get_contour_detections(mask, thresh=500, distance_threshold=55)\n",
    "    rgb_detections = draw_contours(frame, detections)\n",
    "\n",
    "    merged_frame = add_text(merge_images(cv2.cvtColor(mask, cv2.COLOR_GRAY2RGB), rgb_detections), 'MEDIAN FRAME DIFFERENCING')\n",
    "\n",
    "    # Append to list for video\n",
    "    video_frames_mfd.append(merged_frame)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Frames: 100%|█████████▉| 1699/1700 [00:24<00:00, 68.72it/s]\n"
     ]
    }
   ],
   "execution_count": 141
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T09:10:33.798550Z",
     "start_time": "2024-05-19T09:10:31.423043Z"
    }
   },
   "cell_type": "code",
   "source": [
    "os.makedirs(os.path.join(results_folder_path, 'Median Frame Differencing'), exist_ok=True)\n",
    "make_video(video_frames_mfd, os.path.join(results_folder_path, 'Median Frame Differencing', f'{random_sub_category}.mp4'))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Frames: 100%|██████████| 1699/1699 [00:02<00:00, 720.61it/s]\n"
     ]
    }
   ],
   "execution_count": 142
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **Median Frame Differencing with Morphology**\n",
    "### Method\n",
    "1) Calculate the median of buffered frames (previous n frame) to generate a reference frame\n",
    "2) Take Frame Difference: $d = median frame - frame_{t}$\n",
    "3) Threshold frame difference to get mask\n",
    "4) Perform Morphological operations to reduce noise and make the moving objects stand out more\n",
    "5) Perform detection on mask via contour finding\n",
    "6) Draw bounding boxes"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T09:10:58.390719Z",
     "start_time": "2024-05-19T09:10:33.799543Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import deque\n",
    "\n",
    "video_frames_mfd_morph = []\n",
    "buffer_size = 5\n",
    "frame_buffer = deque(maxlen=buffer_size)\n",
    "# Kernel for morphological operations\n",
    "kernel = np.ones((3, 3), np.uint8)\n",
    "\n",
    "for idx in tqdm(range(1, len(image_paths)), total=len(image_paths), desc=\"Processing Frames\"):\n",
    "    frame = cv2.imread(image_paths[idx])\n",
    "    frame_buffer.append(frame)\n",
    "    median_frame = np.median(np.array(frame_buffer), axis=0).astype(np.uint8)\n",
    "    \n",
    "    mask = get_mask(median_frame, frame, True)\n",
    "    # Closing to fill small holes\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    detections = get_contour_detections(mask, thresh=400, distance_threshold=10)\n",
    "    rgb_detections = draw_contours(frame, detections)\n",
    "\n",
    "    merged_frame = add_text(merge_images(cv2.cvtColor(mask, cv2.COLOR_GRAY2RGB), rgb_detections), 'MEDIAN FRAME DIFFERENCING WITH MORPHOLOGY')\n",
    "\n",
    "    # Append to list for video\n",
    "    video_frames_mfd_morph.append(merged_frame)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Frames: 100%|█████████▉| 1699/1700 [00:24<00:00, 69.39it/s]\n"
     ]
    }
   ],
   "execution_count": 143
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T09:11:01.433343Z",
     "start_time": "2024-05-19T09:10:58.391719Z"
    }
   },
   "cell_type": "code",
   "source": [
    "os.makedirs(os.path.join(results_folder_path, 'Median Frame Differencing with Morph'), exist_ok=True)\n",
    "make_video(video_frames_mfd_morph, os.path.join(results_folder_path, 'Median Frame Differencing with Morph', f'{random_sub_category}.mp4'))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Frames: 100%|██████████| 1699/1699 [00:03<00:00, 561.11it/s]\n"
     ]
    }
   ],
   "execution_count": 144
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## **Mixture of Gaussian**"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T09:11:11.862233Z",
     "start_time": "2024-05-19T09:11:01.434345Z"
    }
   },
   "cell_type": "code",
   "source": [
    "video_frames_mog = []\n",
    "kernel = np.ones((2, 2), np.uint8)\n",
    "background_model = cv2.createBackgroundSubtractorMOG2(history=200, varThreshold=50)\n",
    "\n",
    "for idx in tqdm(range(1, len(image_paths)), total=len(image_paths), desc=\"Processing Frames\"):\n",
    "    frame = cv2.imread(image_paths[idx])\n",
    "    \n",
    "    mask = background_model.apply(frame)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "    \n",
    "    detections = get_contour_detections(mask, thresh=200, distance_threshold=25)\n",
    "    rgb_detections = draw_contours(frame, detections)\n",
    "\n",
    "    merged_frame = add_text(merge_images(cv2.cvtColor(mask, cv2.COLOR_GRAY2RGB), rgb_detections), 'MIXTURE OF GAUSSIAN')\n",
    "\n",
    "    # Append to list for video\n",
    "    video_frames_mog.append(merged_frame)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Frames: 100%|█████████▉| 1699/1700 [00:10<00:00, 164.56it/s]\n"
     ]
    }
   ],
   "execution_count": 145
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T09:11:14.479176Z",
     "start_time": "2024-05-19T09:11:11.864234Z"
    }
   },
   "cell_type": "code",
   "source": [
    "os.makedirs(os.path.join(results_folder_path, 'Mixture of Gaussian'), exist_ok=True)\n",
    "make_video(video_frames_mog, os.path.join(results_folder_path, 'Mixture of Gaussian', f'{random_sub_category}.mp4'))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Frames: 100%|██████████| 1699/1699 [00:02<00:00, 652.95it/s]\n"
     ]
    }
   ],
   "execution_count": 146
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T09:11:14.483385Z",
     "start_time": "2024-05-19T09:11:14.480178Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": 146
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6c3515861ec4313dacaa20b0eec5bf326e6557b6589b7b6a4fe3c8baa566747d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
